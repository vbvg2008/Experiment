{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jenno/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are a little better when the dimensionality of the random vector is only 10.\n",
    "# The dimensionality has been left at 100 for consistency with other GAN implementations.\n",
    "randomDim = 100\n",
    "\n",
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data('/home/jenno/Desktop/data/mnist/mnist.npz')\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "\n",
    "# Optimizer\n",
    "adam = Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_dim=randomDim))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(784, activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(1024, input_dim=784))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(512))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "discriminator.trainable = False\n",
    "# Combined network\n",
    "ganInput = Input(shape=(randomDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "\n",
    "dLosses = []\n",
    "gLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss from each batch\n",
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dLosses, label='Discriminitive loss')\n",
    "    plt.plot(gLosses, label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('reference/images/gan_loss_epoch_%d.png' % epoch)\n",
    "\n",
    "# Create a wall of generated MNIST images\n",
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, randomDim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reference/images/gan_generated_image_epoch_%d.png' % epoch)\n",
    "\n",
    "# Save the generator and discriminator networks (and weights) for later use\n",
    "def saveModels(epoch):\n",
    "    generator.save('reference/models/gan_generator_epoch_%d.h5' % epoch)\n",
    "    discriminator.save('reference/models/gan_discriminator_epoch_%d.h5' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = X_train.shape[0] // batchSize\n",
    "    for e in range(epochs):\n",
    "        print('Epoch %d' % e)\n",
    "        epoch_dLoss = []\n",
    "        epoch_gLoss = []\n",
    "        for i in range(batchCount):\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
    "\n",
    "            # Generate fake MNIST images\n",
    "            generatedImages = generator.predict(noise)\n",
    "            # print np.shape(imageBatch), np.shape(generatedImages)\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            yDis = np.zeros(2*batchSize)\n",
    "            # One-sided label smoothing\n",
    "            yDis[:batchSize] = 0.9\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yDis)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "            epoch_dLoss.append(dloss)\n",
    "            epoch_gLoss.append(gloss)\n",
    "            print(gloss)\n",
    "        average_dloss = np.mean(epoch_dLoss)\n",
    "        average_gloss = np.mean(epoch_gLoss)\n",
    "        print('generator loss: ' + str(average_gloss))\n",
    "        print('discriminator loss: ' + str(average_dloss))\n",
    "        dLosses.append(average_dloss)\n",
    "        gLosses.append(average_gloss)\n",
    "\n",
    "        if e % 50 == 0 and e != 0:\n",
    "            plotGeneratedImages(e)\n",
    "            #saveModels(e)\n",
    "\n",
    "    # Plot losses from every epoch\n",
    "    plotLoss(e)\n",
    "    print('training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Total params: 2,920,450\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 1,460,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               803600    \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "0.72320676\n",
      "0.687928\n",
      "0.6367873\n",
      "0.6373629\n",
      "0.60917264\n",
      "0.5891676\n",
      "0.58692336\n",
      "0.57869315\n",
      "0.56545186\n",
      "0.5843009\n",
      "0.5677943\n",
      "0.5963724\n",
      "0.58628345\n",
      "0.62779343\n",
      "0.65469533\n",
      "0.7047914\n",
      "0.7354696\n",
      "0.79410154\n",
      "0.8483566\n",
      "0.8992345\n",
      "0.9431421\n",
      "1.0078995\n",
      "1.0443285\n",
      "1.0699167\n",
      "1.0961827\n",
      "1.1136625\n",
      "1.1668453\n",
      "1.1454762\n",
      "1.1911232\n",
      "1.2213593\n",
      "1.1964948\n",
      "1.2214944\n",
      "1.2705653\n",
      "1.3129435\n",
      "1.3011277\n",
      "1.417846\n",
      "1.3889898\n",
      "1.3414229\n",
      "1.358686\n",
      "1.3265721\n",
      "1.3743792\n",
      "1.3133378\n",
      "1.2784407\n",
      "1.4106313\n",
      "1.4418548\n",
      "1.5404128\n",
      "1.586438\n",
      "1.6454166\n",
      "1.6384704\n",
      "1.7532828\n",
      "1.800461\n",
      "1.8311273\n",
      "1.8289931\n",
      "1.7472836\n",
      "1.6929898\n",
      "1.7014805\n",
      "1.7985859\n",
      "1.7180855\n",
      "1.786087\n",
      "1.9060388\n",
      "1.8484626\n",
      "1.8900132\n",
      "1.9892137\n",
      "1.9140078\n",
      "1.9377034\n",
      "2.0177548\n",
      "1.9559952\n",
      "2.0953033\n",
      "2.191064\n",
      "2.2512534\n",
      "2.4410396\n",
      "2.4647865\n",
      "2.6205301\n",
      "2.6535451\n",
      "2.8307905\n",
      "2.970058\n",
      "3.1039038\n",
      "3.26375\n",
      "3.4225955\n",
      "3.5885348\n",
      "3.7471168\n",
      "3.8536074\n",
      "3.7080767\n",
      "3.650783\n",
      "3.4495795\n",
      "3.3362417\n",
      "3.2622042\n",
      "2.9105792\n",
      "3.1295025\n",
      "3.0554533\n",
      "2.9903398\n",
      "3.0031004\n",
      "2.9657657\n",
      "3.0118566\n",
      "3.2216997\n",
      "3.1792932\n",
      "3.292562\n",
      "3.3657894\n",
      "3.3687973\n",
      "3.3394523\n",
      "3.3362646\n",
      "3.169114\n",
      "3.1969926\n",
      "2.82293\n",
      "2.714781\n",
      "2.2615442\n",
      "2.017324\n",
      "1.8062716\n",
      "1.7025099\n",
      "1.7055042\n",
      "1.5321941\n",
      "1.4820889\n",
      "1.4092228\n",
      "1.3282645\n",
      "1.3130091\n",
      "1.2537348\n",
      "1.2591767\n",
      "1.4136031\n",
      "1.6580788\n",
      "1.983507\n",
      "2.2942224\n",
      "2.6732895\n",
      "3.1152534\n",
      "3.1071427\n",
      "3.2340949\n",
      "3.4019234\n",
      "3.365569\n",
      "3.3009617\n",
      "3.1121376\n",
      "2.9474304\n",
      "2.8490233\n",
      "2.7977104\n",
      "2.4132817\n",
      "2.106756\n",
      "1.8250177\n",
      "1.6434925\n",
      "1.442593\n",
      "1.3489172\n",
      "1.1008911\n",
      "0.85969007\n",
      "0.73048127\n",
      "0.6222722\n",
      "0.6730958\n",
      "0.70708567\n",
      "0.78449047\n",
      "0.9200306\n",
      "1.1441855\n",
      "1.3845894\n",
      "1.5697474\n",
      "1.9342532\n",
      "2.1877522\n",
      "2.5347083\n",
      "2.9279518\n",
      "3.415225\n",
      "3.8101373\n",
      "3.9530401\n",
      "3.9730988\n",
      "3.8320117\n",
      "3.7997742\n",
      "3.6103816\n",
      "3.3362207\n",
      "2.9628286\n",
      "2.7688446\n",
      "2.4343505\n",
      "2.2270103\n",
      "2.1402817\n",
      "2.0428376\n",
      "2.0417137\n",
      "2.077768\n",
      "1.9245665\n",
      "1.9854268\n",
      "2.0645723\n",
      "1.9903425\n",
      "1.9577117\n",
      "1.8889353\n",
      "1.9575714\n",
      "1.7504376\n",
      "1.5862958\n",
      "1.5722928\n",
      "1.5288348\n",
      "1.6076851\n",
      "1.8791599\n",
      "2.2102523\n",
      "2.7409804\n",
      "3.2850153\n",
      "3.5003343\n",
      "3.9010203\n",
      "3.9214988\n",
      "3.7174041\n",
      "3.6448457\n",
      "3.1093862\n",
      "2.6051095\n",
      "2.6863573\n",
      "2.3480506\n",
      "2.2294996\n",
      "1.8995987\n",
      "1.9463017\n",
      "1.7659488\n",
      "1.4810885\n",
      "1.3959246\n",
      "1.2834789\n",
      "1.4140018\n",
      "1.3932713\n",
      "1.2068263\n",
      "1.2230526\n",
      "1.2004613\n",
      "1.2666366\n",
      "1.4338852\n",
      "1.6810738\n",
      "1.7731144\n",
      "2.1446555\n",
      "2.3354335\n",
      "2.4070616\n",
      "2.4729428\n",
      "2.6088886\n",
      "2.6827672\n",
      "2.8308907\n",
      "2.8401556\n",
      "2.9712508\n",
      "2.8204558\n",
      "2.6302803\n",
      "2.4996824\n",
      "2.5652306\n",
      "2.3395753\n",
      "2.3739958\n",
      "2.3691475\n",
      "2.484707\n",
      "2.4009418\n",
      "2.8037536\n",
      "2.7202268\n",
      "2.8405097\n",
      "2.7387972\n",
      "2.8637233\n",
      "2.9158509\n",
      "2.905969\n",
      "2.795212\n",
      "2.5215871\n",
      "2.613305\n",
      "2.8257987\n",
      "2.7506537\n",
      "2.8074646\n",
      "2.2367132\n",
      "2.244101\n",
      "2.4520476\n",
      "2.79808\n",
      "2.945052\n",
      "2.7788267\n",
      "2.90356\n",
      "2.8480067\n",
      "3.1155984\n",
      "3.2564707\n",
      "3.548994\n",
      "3.515306\n",
      "3.7253745\n",
      "3.9623675\n",
      "3.7144969\n",
      "3.6499302\n",
      "3.7372384\n",
      "3.8455837\n",
      "4.084408\n",
      "3.7566547\n",
      "4.051834\n",
      "3.984684\n",
      "3.7069914\n",
      "3.9158468\n",
      "3.510222\n",
      "3.935733\n",
      "4.1710706\n",
      "4.212212\n",
      "4.15839\n",
      "3.9975848\n",
      "4.461343\n",
      "4.290514\n",
      "4.993098\n",
      "5.4489727\n",
      "5.9243107\n",
      "5.6418743\n",
      "6.2328467\n",
      "5.7505636\n",
      "5.4789205\n",
      "5.1509237\n",
      "5.123833\n",
      "5.084002\n",
      "5.413459\n",
      "5.5889263\n",
      "4.9230285\n",
      "4.715953\n",
      "4.353163\n",
      "4.51672\n",
      "5.3781977\n",
      "5.3429\n",
      "5.309269\n",
      "4.880624\n",
      "4.3544693\n",
      "4.2193174\n",
      "3.8993406\n",
      "4.085175\n",
      "3.855199\n",
      "3.7181168\n",
      "2.692597\n",
      "2.0977483\n",
      "2.0531158\n",
      "2.1488202\n",
      "2.1617742\n",
      "2.3646555\n",
      "3.2195878\n",
      "4.2580004\n",
      "4.9568024\n",
      "5.7879076\n",
      "6.15262\n",
      "5.7173033\n",
      "5.2917337\n",
      "4.553952\n",
      "4.204907\n",
      "3.4216309\n",
      "3.4301872\n",
      "3.3153472\n",
      "3.2798955\n",
      "3.113606\n",
      "2.8176198\n",
      "2.3925662\n",
      "2.1847448\n",
      "2.274242\n",
      "2.443543\n",
      "2.561727\n",
      "2.5353606\n",
      "1.8689817\n",
      "1.8169527\n",
      "1.6759187\n",
      "1.5811272\n",
      "1.7797444\n",
      "1.7649564\n",
      "1.8869334\n",
      "2.0355084\n",
      "1.898612\n",
      "2.0366635\n",
      "1.9544752\n",
      "1.8909082\n",
      "2.2656913\n",
      "2.474067\n",
      "2.5943415\n",
      "2.6362333\n",
      "2.7357578\n",
      "3.0638368\n",
      "3.2082696\n",
      "4.044877\n",
      "4.361965\n",
      "4.4219403\n",
      "4.6530113\n",
      "4.307313\n",
      "3.6626875\n",
      "3.7915037\n",
      "3.7729712\n",
      "4.0608425\n",
      "4.1598797\n",
      "4.414265\n",
      "4.098365\n",
      "3.526048\n",
      "3.0831308\n",
      "2.7787967\n",
      "3.4943802\n",
      "4.011906\n",
      "3.5613527\n",
      "2.7810519\n",
      "2.7096698\n",
      "2.854156\n",
      "3.0439405\n",
      "3.2201414\n",
      "2.8402267\n",
      "2.55369\n",
      "2.8107128\n",
      "2.8132231\n",
      "2.9751992\n",
      "3.37773\n",
      "4.29913\n",
      "4.060505\n",
      "4.4496365\n",
      "4.078713\n",
      "3.9678037\n",
      "4.0758543\n",
      "4.5376716\n",
      "5.2397966\n",
      "5.1630745\n",
      "5.1003113\n",
      "4.775831\n",
      "4.8084383\n",
      "4.543009\n",
      "4.550759\n",
      "5.2966733\n",
      "5.838866\n",
      "6.592143\n",
      "6.474908\n",
      "6.5721607\n",
      "5.941986\n",
      "5.5880914\n",
      "5.2368007\n",
      "5.144822\n",
      "5.3281846\n",
      "5.5283666\n",
      "5.9962816\n",
      "5.8952208\n",
      "6.287596\n",
      "5.5740438\n",
      "5.1998553\n",
      "4.3278403\n",
      "4.218011\n",
      "4.67079\n",
      "4.721822\n",
      "4.965173\n",
      "4.340701\n",
      "4.6553593\n",
      "4.661449\n",
      "4.582489\n",
      "4.8160524\n",
      "4.4640274\n",
      "4.265876\n",
      "4.209035\n",
      "3.822403\n",
      "4.1019053\n",
      "4.5839453\n",
      "4.6775374\n",
      "5.0095677\n",
      "5.002231\n",
      "5.351782\n",
      "5.9984894\n",
      "6.193321\n",
      "6.703113\n",
      "6.6331873\n",
      "6.6507063\n",
      "5.9987583\n",
      "5.6867247\n",
      "5.4696407\n",
      "5.075984\n",
      "4.76937\n",
      "4.63354\n",
      "4.4806843\n",
      "4.5499496\n",
      "4.4584875\n",
      "4.371956\n",
      "4.1869063\n",
      "4.247901\n",
      "3.850081\n",
      "4.282947\n",
      "4.4863997\n",
      "4.033646\n",
      "3.9259117\n",
      "3.5247207\n",
      "2.6926787\n",
      "2.705598\n",
      "2.5436118\n",
      "2.7182515\n",
      "2.0980537\n",
      "1.4108343\n",
      "0.99875784\n",
      "0.93191695\n",
      "1.1721652\n",
      "1.3483605\n",
      "1.7823449\n",
      "1.8363838\n",
      "1.6565166\n",
      "1.8740752\n",
      "1.7808161\n",
      "2.3790765\n",
      "2.7988987\n",
      "3.250861\n",
      "3.7558038\n",
      "3.8606067\n",
      "3.824082\n",
      "generator loss: 2.9808497\n",
      "discriminator loss: 0.45811564\n",
      "Epoch 1\n",
      "3.6621065\n",
      "3.6598408\n",
      "3.3455539\n",
      "3.295787\n",
      "3.293789\n",
      "3.684925\n",
      "3.8475575\n",
      "3.8561575\n",
      "3.4351487\n",
      "3.1094813\n",
      "2.9417431\n",
      "3.14463\n",
      "3.3945045\n",
      "3.8175855\n",
      "3.8573267\n",
      "4.471435\n",
      "4.156851\n",
      "3.8208704\n",
      "3.5317461\n",
      "3.9377007\n",
      "3.4671612\n",
      "3.2343588\n",
      "3.1117413\n",
      "2.9455485\n",
      "2.6514087\n",
      "2.4203901\n",
      "2.2816353\n",
      "2.3349168\n",
      "1.7808177\n",
      "1.8815942\n",
      "1.685683\n",
      "1.4202046\n",
      "1.2330608\n",
      "0.9696425\n",
      "0.7770061\n",
      "1.0143661\n",
      "0.94374955\n",
      "1.0253642\n",
      "1.4400887\n",
      "1.5973861\n",
      "1.6073533\n",
      "1.6873887\n",
      "1.5781803\n",
      "1.5798359\n",
      "1.6294053\n",
      "2.1070771\n",
      "2.4111722\n",
      "2.6034544\n",
      "3.0321548\n",
      "3.5139046\n",
      "3.3494482\n",
      "3.2835312\n",
      "3.4244862\n",
      "3.4448333\n",
      "3.9809473\n",
      "4.3199835\n",
      "4.6960773\n",
      "4.7961874\n",
      "4.780778\n",
      "4.8203425\n",
      "4.5897818\n",
      "4.4539075\n",
      "4.148347\n",
      "4.0745044\n",
      "3.6771834\n",
      "3.626451\n",
      "3.7472181\n",
      "3.6334085\n",
      "3.5234053\n",
      "3.0855408\n",
      "2.9811172\n",
      "3.2409358\n",
      "3.1930714\n",
      "2.9451244\n",
      "2.78575\n",
      "2.572792\n",
      "2.3343673\n",
      "2.1133482\n",
      "2.1125045\n",
      "1.95487\n",
      "2.0830784\n",
      "2.003136\n",
      "1.8657984\n",
      "2.0324755\n",
      "1.9862084\n",
      "2.053443\n",
      "2.312958\n",
      "2.205336\n",
      "2.761592\n",
      "3.0550423\n",
      "3.3477788\n",
      "3.5838046\n",
      "3.583859\n",
      "3.6987991\n",
      "3.5712829\n",
      "3.4976263\n",
      "3.413817\n",
      "3.2617264\n",
      "3.2315948\n",
      "3.4096565\n",
      "3.6874323\n",
      "3.5876894\n",
      "3.4432492\n",
      "3.0640237\n",
      "2.9544556\n",
      "2.4281244\n",
      "2.4093785\n",
      "2.1252408\n",
      "2.2334785\n",
      "2.3536835\n",
      "2.2871323\n",
      "2.2926965\n",
      "2.1677322\n",
      "2.032512\n",
      "2.1201398\n",
      "1.9195702\n",
      "1.8191389\n",
      "1.7701018\n",
      "2.1054442\n",
      "2.2802265\n",
      "2.520778\n",
      "2.5004458\n",
      "2.5288987\n",
      "2.5911436\n",
      "2.6427407\n",
      "2.8958678\n",
      "2.8034086\n",
      "3.1998863\n",
      "3.2111514\n",
      "3.070744\n",
      "2.9674416\n",
      "2.599592\n",
      "2.4003315\n",
      "2.4753942\n",
      "2.2740648\n",
      "2.3635693\n",
      "2.1535854\n",
      "2.4329462\n",
      "2.207169\n",
      "2.1429791\n",
      "1.7486522\n",
      "1.6256001\n",
      "1.6450164\n",
      "1.845962\n",
      "2.0903811\n",
      "1.838959\n",
      "1.8053843\n",
      "1.961247\n",
      "1.9295163\n",
      "2.11653\n",
      "2.3109648\n",
      "2.81743\n",
      "2.9281316\n",
      "2.3153923\n",
      "2.127576\n",
      "2.1449156\n",
      "2.2943277\n",
      "2.9343295\n",
      "3.065189\n",
      "3.0943463\n",
      "2.4780512\n",
      "2.2619228\n",
      "1.9933794\n",
      "2.2766461\n",
      "2.3115792\n",
      "2.6407924\n",
      "2.61289\n",
      "2.4745193\n",
      "2.1841898\n",
      "1.9943199\n",
      "2.023941\n",
      "2.3297107\n",
      "2.4970002\n",
      "2.4423923\n",
      "2.6191926\n",
      "2.260549\n",
      "2.1381173\n",
      "1.9840064\n",
      "2.1081202\n",
      "2.570724\n",
      "2.6590478\n",
      "2.798395\n",
      "2.8156567\n",
      "2.6069722\n",
      "2.681806\n",
      "2.788943\n",
      "3.259924\n",
      "3.2972383\n",
      "3.790742\n",
      "4.0709915\n",
      "3.9655483\n",
      "3.773806\n",
      "3.9318993\n",
      "3.2070608\n",
      "3.2813601\n",
      "3.2800298\n",
      "3.4414296\n",
      "3.5067098\n",
      "3.863669\n",
      "3.5169134\n",
      "3.7099457\n",
      "3.1884084\n",
      "2.894976\n",
      "2.5435774\n",
      "2.5801177\n",
      "2.6682987\n",
      "2.4275243\n",
      "2.4791598\n",
      "2.600455\n",
      "2.6460977\n",
      "2.5795038\n",
      "2.779488\n",
      "3.3108356\n",
      "4.103566\n",
      "4.48761\n",
      "5.449088\n",
      "6.0016527\n",
      "5.5731936\n",
      "5.8348227\n",
      "4.972955\n",
      "4.819804\n",
      "4.0786705\n",
      "3.9750624\n",
      "3.945972\n",
      "4.1704373\n",
      "4.0941315\n",
      "4.0812626\n",
      "3.8944232\n",
      "3.2522666\n",
      "2.985326\n",
      "3.2004275\n",
      "3.685421\n",
      "4.135663\n",
      "4.227095\n",
      "4.467936\n",
      "4.4526615\n",
      "4.0222726\n",
      "3.6086936\n",
      "3.6307583\n",
      "3.6628065\n",
      "3.7073395\n",
      "3.4732308\n",
      "3.5388267\n",
      "3.0959544\n",
      "2.8816233\n",
      "2.7332675\n",
      "2.6344578\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1633aed4a69b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-684d65964eb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batchSize)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# Get a random set of input noise and images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomDim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mimageBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
