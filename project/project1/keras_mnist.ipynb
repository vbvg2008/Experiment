{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jenno/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input,Dense, Softmax\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data('/home/jenno/Desktop/data/mnist/mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (60000, 28*28))\n",
    "x_train = np.float32(x_train)/255\n",
    "y_train = np.int32(y_train)\n",
    "\n",
    "x_test = np.reshape(x_test, (10000, 28*28))\n",
    "x_test = np.float32(x_test)/255\n",
    "y_test = np.int32(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network configuration\n",
    "num_input = 28 * 28\n",
    "num_hidden_1 = 32\n",
    "num_hidden_2 = 32\n",
    "num_ouput = 10\n",
    "num_epoch = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape= [num_input])\n",
    "x = Dense(32, activation='relu')(x_input)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x_output = Dense(num_ouput, activation= 'softmax')(x)\n",
    "model = Model(x_input, x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adamax(0.001)\n",
    "lr_metric = get_lr_metric(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer = optimizer,\n",
    "              metrics=['accuracy', lr_metric])\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_ouput)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./logs/keras',\n",
    "                 histogram_freq=0, \n",
    "                 write_graph=True, \n",
    "                 write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6982 - acc: 0.8129 - lr: 0.0010 - val_loss: 0.3438 - val_acc: 0.9092 - val_lr: 0.0010\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3137 - acc: 0.9118 - lr: 0.0010 - val_loss: 0.2741 - val_acc: 0.9234 - val_lr: 0.0010\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2631 - acc: 0.9263 - lr: 0.0010 - val_loss: 0.2405 - val_acc: 0.9299 - val_lr: 0.0010\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2353 - acc: 0.9324 - lr: 0.0010 - val_loss: 0.2200 - val_acc: 0.9357 - val_lr: 0.0010\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2149 - acc: 0.9386 - lr: 0.0010 - val_loss: 0.2067 - val_acc: 0.9396 - val_lr: 0.0010\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1995 - acc: 0.9440 - lr: 0.0010 - val_loss: 0.1955 - val_acc: 0.9423 - val_lr: 0.0010\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1864 - acc: 0.9469 - lr: 0.0010 - val_loss: 0.1846 - val_acc: 0.9445 - val_lr: 0.0010\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1751 - acc: 0.9492 - lr: 0.0010 - val_loss: 0.1774 - val_acc: 0.9470 - val_lr: 0.0010\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1655 - acc: 0.9526 - lr: 0.0010 - val_loss: 0.1702 - val_acc: 0.9481 - val_lr: 0.0010\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1572 - acc: 0.9549 - lr: 0.0010 - val_loss: 0.1652 - val_acc: 0.9514 - val_lr: 0.0010\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1495 - acc: 0.9570 - lr: 0.0010 - val_loss: 0.1586 - val_acc: 0.9536 - val_lr: 0.0010\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1428 - acc: 0.9592 - lr: 0.0010 - val_loss: 0.1563 - val_acc: 0.9532 - val_lr: 0.0010\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1365 - acc: 0.9607 - lr: 0.0010 - val_loss: 0.1513 - val_acc: 0.9542 - val_lr: 0.0010\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1306 - acc: 0.9623 - lr: 0.0010 - val_loss: 0.1473 - val_acc: 0.9557 - val_lr: 0.0010\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1255 - acc: 0.9641 - lr: 0.0010 - val_loss: 0.1456 - val_acc: 0.9565 - val_lr: 0.0010\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1212 - acc: 0.9646 - lr: 0.0010 - val_loss: 0.1414 - val_acc: 0.9579 - val_lr: 0.0010\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1169 - acc: 0.9663 - lr: 0.0010 - val_loss: 0.1387 - val_acc: 0.9587 - val_lr: 0.0010\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1132 - acc: 0.9672 - lr: 0.0010 - val_loss: 0.1387 - val_acc: 0.9586 - val_lr: 0.0010\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1092 - acc: 0.9683 - lr: 0.0010 - val_loss: 0.1343 - val_acc: 0.9602 - val_lr: 0.0010\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1056 - acc: 0.9692 - lr: 0.0010 - val_loss: 0.1312 - val_acc: 0.9617 - val_lr: 0.0010\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1027 - acc: 0.9704 - lr: 0.0010 - val_loss: 0.1347 - val_acc: 0.9594 - val_lr: 0.0010\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0998 - acc: 0.9707 - lr: 0.0010 - val_loss: 0.1278 - val_acc: 0.9608 - val_lr: 0.0010\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0970 - acc: 0.9715 - lr: 0.0010 - val_loss: 0.1263 - val_acc: 0.9622 - val_lr: 0.0010\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0943 - acc: 0.9723 - lr: 0.0010 - val_loss: 0.1230 - val_acc: 0.9628 - val_lr: 0.0010\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0917 - acc: 0.9730 - lr: 0.0010 - val_loss: 0.1226 - val_acc: 0.9641 - val_lr: 0.0010\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0895 - acc: 0.9740 - lr: 0.0010 - val_loss: 0.1240 - val_acc: 0.9634 - val_lr: 0.0010\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0871 - acc: 0.9746 - lr: 0.0010 - val_loss: 0.1209 - val_acc: 0.9644 - val_lr: 0.0010\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0848 - acc: 0.9750 - lr: 0.0010 - val_loss: 0.1202 - val_acc: 0.9647 - val_lr: 0.0010\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0829 - acc: 0.9759 - lr: 0.0010 - val_loss: 0.1219 - val_acc: 0.9656 - val_lr: 0.0010\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0804 - acc: 0.9767 - lr: 0.0010 - val_loss: 0.1187 - val_acc: 0.9662 - val_lr: 0.0010\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0787 - acc: 0.9768 - lr: 0.0010 - val_loss: 0.1173 - val_acc: 0.9665 - val_lr: 0.0010\n",
      "Epoch 32/50\n",
      "25216/60000 [===========>..................] - ETA: 0s - loss: 0.0759 - acc: 0.9777 - lr: 0.0010"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          validation_data=(x_test, y_test),\n",
    "          verbose=1,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
